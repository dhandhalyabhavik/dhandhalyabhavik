## Hi there ðŸ‘‹

<!--
**dhandhalyabhavik/dhandhalyabhavik** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

- ðŸ”­ Iâ€™m currently working on ... **Intel GPU Optimizations.**

### Past projects:

**2025**

- [ros-benchmark-cpu](https://github.com/intel-sandbox/ros-benchmark-cpu) Replicating NVIDIA's ros-benchmark pipeline but for Intel CPUs. Docker based. It benchmarks huggingface's smolVLA model.
- [llm.chat](https://github.com/dhandhalyabhavik/llm.chat) A front-end for locally hosted models with features such as chat, file-upload, web search, rag, agentic rag etc. It supports external APIs, DeepSeek based OCR for premium pdf textraction, docling based OCR for super fast pdf extraction. Support for max 30 conversations saved in db. The backend repos are [rag-service](https://github.com/dhandhalyabhavik/rag-services) and [OCR-services](https://github.com/dhandhalyabhavik/OCR-services). Everything is dockerbased except front-end.
- [chad.ai](https://github.com/dhandhalyabhavik/chad-ai) is terminal based chat agent that can do light work pretty fast with saved session on tmux terminal. If job is done, it can save successful task as snippets to later perform the same task without human intervention. I am planning to make it open-source soon.
- [Video summarization](https://github.com/intel-sandbox/VideoSummarization) it uses CLIP model to store frame embeddings and summary text embeddings (generated by Qwen 3 VL) in vectordb for video based search & Q&A. It had support of DeepSeek R1 model for complex reasoning question related to video. I contributed to 100% POC code and 30% to extension code of Intel labs. The 100% POC can be found here [visual-rag](https://github.com/dhandhalyabhavik/model_server/tree/visual-rag/demos/python_demos) is the same demo which got featured at Intel Vision. I was awarded DRA for the same.
- [Containment Breach Analytics Agent](https://github.com/intel-sandbox/eapb-agentic-ai-analytics/tree/34d6488fa134b3176a278c6c05d3846e10b1ca50/agentic_workflow_orch) created an automated agent that used locally hosted GLM 4.5 Air model to identify various containment breach from generated report.

**2023-2024**

- [Prefix caching llama.cpp & openvino](https://github.com/intel-sandbox/Prefix-caching-comparison) compared prefix caching performance and BKMs of llama.cpp vs OpenVINO
- [Prefix cache in llama.cpp](https://github.com/intel-sandbox/Prefix-Caching-LLM) implemented user-friendly easier prefix caching wrapper for different conversation caching on top of llama.cpp APIs
- [BLAST](https://github.com/intel-sandbox/BLAST) AI based educational solution that converts any book into interactive Q&A session for given chapter, subtopic or page. It tracks your learning by quizing you per chapter per subtopic. The process is entirely automatted. Used llama 3.2 model to generate MCQ, used self-verification technique to discard rubbish or incorrect MCQs.
- [AI based closed loop automation for energy management(1 year+ long project)](https://github.com/intel-sandbox/applications.services.nase-pathfinding-repos.springvalley/tree/main/src/close-loop-automation) given daily load pattern, AI understands the load, h/w configurations and predicts future hardware configuration to preserve same application performance at lower power. It resulted in 12-30% power saving and sometime as max as 42% in best case. Filed for patent (but rejected). Won DRA for this work.


other repos:

- [Bandwidth testing tool docker based for Intel GPUs](https://github.com/intel-sandbox/intel-gpu-bandwidth-test) It uses OpenCL to benchmark bandwidth on Intel GPUs entirely runs on docker
- [Intel-openvino docker image for B60 GPU](https://github.com/intel-sandbox/openvino-docker-build-b60-gpu) it builds docker image with openvino source build installation for B60 GPU
- [Intel-xpu Docker image for B60 GPU](https://github.com/intel-sandbox/intel-xpu-docker-test) contains working dockerfile with Intel B60 GPU driver using ipex pytorch extension
- [Intel vs NVIDIA robotics comp analysis](https://github.com/intel-sandbox/Robotics-comp-analysis) contains pipeline & component level comparison between Intel & NVIDIA on their robotics offerings



### Open-source work:

- [GLM 4.5 tool calling support in llama.cpp](https://github.com/ggml-org/llama.cpp/pull/15186) Tried adding tool calling support in llama.cpp but unfortunately due to complex XML and json parsing it didn't go through. At the time of PR, llama.cpp only had json based tool parsing support internally for grammer so GLM 4.5 failed on complex test. I was able to make it work with Claude Code 80% of the time though. 
